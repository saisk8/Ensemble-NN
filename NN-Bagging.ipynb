{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import History\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.datasets import cifar10\n",
    "from keras.engine import training\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Activation, Average\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Model, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.python.framework.ops import Tensor\n",
    "from typing import Tuple, List\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data() -> Tuple [np.ndarray, np.ndarray, \n",
    "                          np.ndarray, np.ndarray]:\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    x_train = x_train / 255.\n",
    "    x_test = x_test / 255.\n",
    "    y_train = to_categorical(y_train, num_classes=10)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "x_train, x_test, y_train, y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3) | y_train shape: (50000, 10)\n",
      "x_test shape : (10000, 32, 32, 3) | y_test shape : (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape: {} | y_train shape: {}\\nx_test shape : {} | y_test shape : {}'.format(x_train.shape, y_train.shape, \n",
    "                                                                                            x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_train[0,:,:,:].shape\n",
    "model_input = Input(shape=input_shape)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_pool_cnn(model_input: Tensor) -> training.Model:\n",
    "    \n",
    "    x = Conv2D(96, kernel_size=(3, 3), activation='relu', padding = 'same')(model_input)\n",
    "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(10, (1, 1))(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation(activation='softmax')(x)\n",
    "    \n",
    "    model = Model(model_input, x, name='conv_pool_cnn')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_pool_cnn_model = conv_pool_cnn(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20\n",
    "def compile_and_train(model: training.Model, num_epochs: int, x_train, y_train) -> Tuple [History, str]: \n",
    "    \n",
    "    model.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['acc']) \n",
    "    filepath = 'weights/' + model.name + '.{epoch:02d}-{loss:.2f}.hdf5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_weights_only=True,\n",
    "                                                 save_best_only=True, mode='auto', period=1)\n",
    "    tensor_board = TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=32)\n",
    "    history = model.fit(x=x_train, y=y_train, batch_size=32, \n",
    "                     epochs=num_epochs, verbose=1, callbacks=[checkpoint, tensor_board], validation_split=0.2)\n",
    "    weight_files = glob.glob(os.path.join(os.getcwd(), 'weights/*'))\n",
    "    weight_file = max(weight_files, key=os.path.getctime) # most recent file\n",
    "    return history, weight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, conv_pool_cnn_weight_file = compile_and_train(conv_pool_cnn_model, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_error(model: training.Model) -> np.float64:\n",
    "    pred = model.predict(x_test, batch_size = 32)\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    pred = np.expand_dims(pred, axis=1) # make same shape as y_test\n",
    "    error = np.sum(np.not_equal(pred, y_test)) / y_test.shape[0]   \n",
    " \n",
    "    return error\n",
    "# (1 - evaluate_error(conv_pool_cnn_model)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_cnn(model_input: Tensor) -> training.Model:\n",
    "    \n",
    "    x = Conv2D(96, kernel_size=(3, 3), activation='relu', padding = 'same')(model_input)\n",
    "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same', strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same', strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(10, (1, 1))(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation(activation='softmax')(x)\n",
    "        \n",
    "    model = Model(model_input, x, name='all_cnn')\n",
    "    \n",
    "    return model\n",
    "all_cnn_model = all_cnn(model_input)\n",
    "# _, all_cnn_weight_file = compile_and_train(all_cnn_model, NUM_EPOCHS)\n",
    "\n",
    "\n",
    "# print('Error for model 2:', 1 - evaluate_error(all_cnn_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nin_cnn(model_input: Tensor) -> training.Model:\n",
    "    \n",
    "    #mlpconv block 1\n",
    "    x = Conv2D(32, (5, 5), activation='relu',padding='valid')(model_input)\n",
    "    x = Conv2D(32, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(32, (1, 1), activation='relu')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    #mlpconv block2\n",
    "    x = Conv2D(64, (3, 3), activation='relu',padding='valid')(x)\n",
    "    x = Conv2D(64, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(64, (1, 1), activation='relu')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    #mlpconv block3\n",
    "    x = Conv2D(128, (3, 3), activation='relu',padding='valid')(x)\n",
    "    x = Conv2D(32, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(10, (1, 1))(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation(activation='softmax')(x)\n",
    "    \n",
    "    model = Model(model_input, x, name='nin_cnn')\n",
    "    \n",
    "    return model\n",
    "\n",
    "nin_cnn_model = nin_cnn(model_input)\n",
    "\n",
    "\n",
    "# _, nin_cnn_weight_file = compile_and_train(nin_cnn_model, NUM_EPOCHS)\n",
    "\n",
    "# print('Error for model 3:', 1 - evaluate_error(all_cnn_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 25s 629us/step - loss: 1.8020 - acc: 0.3064 - val_loss: 1.4576 - val_acc: 0.4610\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 24s 593us/step - loss: 1.3043 - acc: 0.5213 - val_loss: 1.1141 - val_acc: 0.5918\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 24s 597us/step - loss: 1.0128 - acc: 0.6382 - val_loss: 0.9345 - val_acc: 0.6658\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 24s 602us/step - loss: 0.7991 - acc: 0.7208 - val_loss: 0.7397 - val_acc: 0.7441\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 24s 604us/step - loss: 0.6393 - acc: 0.7786 - val_loss: 0.7171 - val_acc: 0.7543\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 24s 611us/step - loss: 0.5116 - acc: 0.8228 - val_loss: 0.5943 - val_acc: 0.8037\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 25s 633us/step - loss: 0.4139 - acc: 0.8579 - val_loss: 0.5930 - val_acc: 0.8157\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 25s 626us/step - loss: 0.3331 - acc: 0.8885 - val_loss: 0.5512 - val_acc: 0.8297\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 24s 612us/step - loss: 0.2705 - acc: 0.9072 - val_loss: 0.5328 - val_acc: 0.8396\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 24s 593us/step - loss: 0.2252 - acc: 0.9222 - val_loss: 0.5890 - val_acc: 0.8413\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 24s 611us/step - loss: 0.1848 - acc: 0.9357 - val_loss: 0.5818 - val_acc: 0.8471\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 25s 621us/step - loss: 0.1658 - acc: 0.9421 - val_loss: 0.5638 - val_acc: 0.8545\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 25s 619us/step - loss: 0.1464 - acc: 0.9497 - val_loss: 0.5484 - val_acc: 0.8721\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 25s 621us/step - loss: 0.1369 - acc: 0.9532 - val_loss: 0.6252 - val_acc: 0.8604\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 25s 621us/step - loss: 0.1236 - acc: 0.9568 - val_loss: 0.6562 - val_acc: 0.8633\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 25s 619us/step - loss: 0.1194 - acc: 0.9601 - val_loss: 0.6291 - val_acc: 0.8741\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 25s 618us/step - loss: 0.1130 - acc: 0.9619 - val_loss: 0.6068 - val_acc: 0.8714\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 25s 619us/step - loss: 0.1034 - acc: 0.9655 - val_loss: 0.6789 - val_acc: 0.8625\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 25s 621us/step - loss: 0.1072 - acc: 0.9640 - val_loss: 0.6306 - val_acc: 0.8622\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 25s 620us/step - loss: 0.0975 - acc: 0.9671 - val_loss: 0.6535 - val_acc: 0.8772\n",
      "Error for model: 0.7436\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 24s 596us/step - loss: 2.3022 - acc: 0.1053 - val_loss: 2.3028 - val_acc: 0.0930\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 23s 578us/step - loss: 2.3027 - acc: 0.0997 - val_loss: 2.3029 - val_acc: 0.0930\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 23s 575us/step - loss: 2.3027 - acc: 0.1009 - val_loss: 2.3030 - val_acc: 0.0930\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 23s 576us/step - loss: 2.3027 - acc: 0.1021 - val_loss: 2.3027 - val_acc: 0.1047\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 23s 572us/step - loss: 2.3027 - acc: 0.0996 - val_loss: 2.3031 - val_acc: 0.0930\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 23s 572us/step - loss: 2.3026 - acc: 0.1012 - val_loss: 2.3030 - val_acc: 0.0930\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 23s 573us/step - loss: 2.3026 - acc: 0.0998 - val_loss: 2.3028 - val_acc: 0.1047\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 23s 573us/step - loss: 2.3027 - acc: 0.1016 - val_loss: 2.3028 - val_acc: 0.1005\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 23s 574us/step - loss: 2.3027 - acc: 0.0994 - val_loss: 2.3029 - val_acc: 0.0930\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 23s 573us/step - loss: 2.3027 - acc: 0.1008 - val_loss: 2.3029 - val_acc: 0.1047\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 23s 570us/step - loss: 2.3027 - acc: 0.0985 - val_loss: 2.3029 - val_acc: 0.1047\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 23s 573us/step - loss: 2.3027 - acc: 0.1021 - val_loss: 2.3028 - val_acc: 0.1047\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 23s 573us/step - loss: 2.3026 - acc: 0.1012 - val_loss: 2.3028 - val_acc: 0.1047\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 23s 573us/step - loss: 2.3026 - acc: 0.1003 - val_loss: 2.3029 - val_acc: 0.1047\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 23s 571us/step - loss: 2.3026 - acc: 0.1004 - val_loss: 2.3030 - val_acc: 0.0930\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 23s 571us/step - loss: 2.3027 - acc: 0.1000 - val_loss: 2.3029 - val_acc: 0.0930\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 23s 574us/step - loss: 2.3026 - acc: 0.0989 - val_loss: 2.3029 - val_acc: 0.0930\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 23s 571us/step - loss: 2.3026 - acc: 0.1002 - val_loss: 2.3029 - val_acc: 0.1047\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 23s 572us/step - loss: 2.3026 - acc: 0.1006 - val_loss: 2.3029 - val_acc: 0.1047\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 23s 571us/step - loss: 2.3027 - acc: 0.1006 - val_loss: 2.3028 - val_acc: 0.1047\n",
      "Error for model: 0.09999999999999998\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 7s 178us/step - loss: 1.8392 - acc: 0.3078 - val_loss: 1.7155 - val_acc: 0.3724\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 7s 163us/step - loss: 1.5438 - acc: 0.4274 - val_loss: 1.4705 - val_acc: 0.4663\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 1.4214 - acc: 0.4799 - val_loss: 1.3319 - val_acc: 0.5129\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 7s 168us/step - loss: 1.3383 - acc: 0.5146 - val_loss: 1.2302 - val_acc: 0.5508\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 1.2762 - acc: 0.5377 - val_loss: 1.1844 - val_acc: 0.5791\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 7s 163us/step - loss: 1.2291 - acc: 0.5564 - val_loss: 1.1339 - val_acc: 0.5942\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.1790 - acc: 0.5764 - val_loss: 1.1026 - val_acc: 0.6076\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 7s 165us/step - loss: 1.1439 - acc: 0.5910 - val_loss: 1.0852 - val_acc: 0.6178\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 1.1127 - acc: 0.6013 - val_loss: 1.0782 - val_acc: 0.6227\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.0886 - acc: 0.6133 - val_loss: 1.0312 - val_acc: 0.6338\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 1.0589 - acc: 0.6250 - val_loss: 1.0116 - val_acc: 0.6479\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.0401 - acc: 0.6315 - val_loss: 0.9490 - val_acc: 0.6654\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 1.0176 - acc: 0.6378 - val_loss: 0.9830 - val_acc: 0.6547\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 7s 163us/step - loss: 0.9950 - acc: 0.6456 - val_loss: 1.0393 - val_acc: 0.6362\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 0.9739 - acc: 0.6543 - val_loss: 0.9948 - val_acc: 0.6553\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 7s 163us/step - loss: 0.9633 - acc: 0.6593 - val_loss: 0.9591 - val_acc: 0.6757\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 0.9479 - acc: 0.6628 - val_loss: 0.8398 - val_acc: 0.7083\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 6s 159us/step - loss: 0.9391 - acc: 0.6647 - val_loss: 0.9801 - val_acc: 0.6690\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 0.9273 - acc: 0.6719 - val_loss: 0.8897 - val_acc: 0.6873\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.9072 - acc: 0.6790 - val_loss: 0.8256 - val_acc: 0.7090\n",
      "Error for model: 0.6658\n"
     ]
    }
   ],
   "source": [
    "models_train = [conv_pool_cnn_model, all_cnn_model, nin_cnn_model]\n",
    "model_weight_file = []\n",
    "\n",
    "\n",
    "def bagging(data, y, n_estimators):\n",
    "    print(data.shape[0])\n",
    "    for m in models_train:\n",
    "        choices = np.random.choice(data.shape[0], data.shape[0], replace=True)\n",
    "        x_train = data[choices,:,:,:]\n",
    "        y_train = y[choices, :]\n",
    "\n",
    "        # Train each classifier on the dataset\n",
    "        _, weight_file = compile_and_train(m, NUM_EPOCHS, x_train, y_train)\n",
    "        model_weight_file.append(weight_file)\n",
    "        print('Accuracy for model:', 1 - evaluate_error(m))       \n",
    "\n",
    "bagging(x_train, y_train, len(models_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for ensemble model: 0.7557\n"
     ]
    }
   ],
   "source": [
    "conv_pool_cnn_model = conv_pool_cnn(model_input)\n",
    "all_cnn_model = all_cnn(model_input)\n",
    "nin_cnn_model = nin_cnn(model_input)\n",
    "\n",
    "conv_pool_cnn_model.load_weights(model_weight_file[0])\n",
    "all_cnn_model.load_weights(model_weight_file[1])\n",
    "nin_cnn_model.load_weights(model_weight_file[2])\n",
    "\n",
    "models = [conv_pool_cnn_model, all_cnn_model, nin_cnn_model]\n",
    "\n",
    "\n",
    "# The ensemble classifier\n",
    "def ensemble(models: List [training.Model], model_input: Tensor) -> training.Model:\n",
    "    \n",
    "    outputs = [model.outputs[0] for model in models]\n",
    "    y = Average()(outputs)\n",
    "    \n",
    "    model = Model(model_input, y, name='ensemble')\n",
    "    \n",
    "    return model\n",
    "\n",
    "ensemble_model = ensemble(models, model_input)\n",
    "\n",
    "\n",
    "print('Accuracy for ensemble model:', 1 - evaluate_error(ensemble_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
