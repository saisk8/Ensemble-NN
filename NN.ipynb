{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.datasets import cifar10\n",
    "from keras.engine import training\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Activation, Average\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Model, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.python.framework.ops import Tensor\n",
    "from typing import Tuple, List\n",
    "import glob\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data() -> Tuple [np.ndarray, np.ndarray, \n",
    "                          np.ndarray, np.ndarray]:\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    x_train = x_train / 255.\n",
    "    x_test = x_test / 255.\n",
    "    y_train = to_categorical(y_train, num_classes=10)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "x_train, x_test, y_train, y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3) | y_train shape: (50000, 10)\n",
      "x_test shape : (10000, 32, 32, 3) | y_test shape : (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape: {} | y_train shape: {}\\nx_test shape : {} | y_test shape : {}'.format(x_train.shape, y_train.shape, \n",
    "                                                                                            x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train[0,:,:,:].shape\n",
    "model_input = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_pool_cnn(model_input: Tensor) -> training.Model:\n",
    "    \n",
    "    x = Conv2D(96, kernel_size=(3, 3), activation='relu', padding = 'same')(model_input)\n",
    "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(10, (1, 1))(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation(activation='softmax')(x)\n",
    "    \n",
    "    model = Model(model_input, x, name='conv_pool_cnn')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_pool_cnn_model = conv_pool_cnn(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20\n",
    "def compile_and_train(model: training.Model, num_epochs: int) -> Tuple [History, str]: \n",
    "    \n",
    "    model.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['acc']) \n",
    "    filepath = 'weights/' + model.name + '.{epoch:02d}-{loss:.2f}.hdf5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_weights_only=True,\n",
    "                                                 save_best_only=True, mode='auto', period=1)\n",
    "    tensor_board = TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=32)\n",
    "    history = model.fit(x=x_train, y=y_train, batch_size=32, \n",
    "                     epochs=num_epochs, verbose=1, callbacks=[checkpoint, tensor_board], validation_split=0.2)\n",
    "    weight_files = glob.glob(os.path.join(os.getcwd(), 'weights/*'))\n",
    "    weight_file = max(weight_files, key=os.path.getctime) # most recent file\n",
    "    return history, weight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 25s 620us/step - loss: 2.0245 - acc: 0.2202 - val_loss: 1.7044 - val_acc: 0.3624\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 24s 594us/step - loss: 1.5494 - acc: 0.4228 - val_loss: 1.3485 - val_acc: 0.5012\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 24s 592us/step - loss: 1.2703 - acc: 0.5398 - val_loss: 1.2550 - val_acc: 0.5450\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 24s 588us/step - loss: 1.0590 - acc: 0.6224 - val_loss: 0.9637 - val_acc: 0.6593\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 23s 583us/step - loss: 0.9154 - acc: 0.6742 - val_loss: 0.9065 - val_acc: 0.6838\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 23s 584us/step - loss: 0.8032 - acc: 0.7168 - val_loss: 0.8454 - val_acc: 0.7083\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 23s 583us/step - loss: 0.7133 - acc: 0.7471 - val_loss: 0.8009 - val_acc: 0.7223\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 23s 584us/step - loss: 0.6354 - acc: 0.7757 - val_loss: 0.7909 - val_acc: 0.7255\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 23s 585us/step - loss: 0.5588 - acc: 0.8044 - val_loss: 0.7754 - val_acc: 0.7367\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 24s 588us/step - loss: 0.4990 - acc: 0.8235 - val_loss: 0.7758 - val_acc: 0.7452\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 24s 588us/step - loss: 0.4327 - acc: 0.8467 - val_loss: 0.8267 - val_acc: 0.7391\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 24s 594us/step - loss: 0.3716 - acc: 0.8685 - val_loss: 0.8362 - val_acc: 0.7418\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 24s 591us/step - loss: 0.3241 - acc: 0.8857 - val_loss: 0.8677 - val_acc: 0.7513\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 24s 599us/step - loss: 0.2775 - acc: 0.9012 - val_loss: 0.9504 - val_acc: 0.7401\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 24s 593us/step - loss: 0.2436 - acc: 0.9132 - val_loss: 0.9320 - val_acc: 0.7490\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 25s 615us/step - loss: 0.2163 - acc: 0.9235 - val_loss: 1.0440 - val_acc: 0.7441\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 24s 591us/step - loss: 0.1963 - acc: 0.9304 - val_loss: 1.1170 - val_acc: 0.7454\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 24s 591us/step - loss: 0.1758 - acc: 0.9394 - val_loss: 1.1679 - val_acc: 0.7383\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 24s 589us/step - loss: 0.1610 - acc: 0.9445 - val_loss: 1.2025 - val_acc: 0.7446\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 24s 590us/step - loss: 0.1556 - acc: 0.9467 - val_loss: 1.1873 - val_acc: 0.7475\n"
     ]
    }
   ],
   "source": [
    "_, conv_pool_cnn_weight_file = compile_and_train(conv_pool_cnn_model, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.47"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_error(model: training.Model) -> np.float64:\n",
    "    pred = model.predict(x_test, batch_size = 32)\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    pred = np.expand_dims(pred, axis=1) # make same shape as y_test\n",
    "    error = np.sum(np.not_equal(pred, y_test)) / y_test.shape[0]   \n",
    " \n",
    "    return error\n",
    "(1 - evaluate_error(conv_pool_cnn_model)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 24s 589us/step - loss: 1.7788 - acc: 0.3217 - val_loss: 1.5477 - val_acc: 0.4187\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 22s 559us/step - loss: 1.3593 - acc: 0.4954 - val_loss: 1.1841 - val_acc: 0.5686\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 22s 561us/step - loss: 1.0798 - acc: 0.6113 - val_loss: 0.9682 - val_acc: 0.6497\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 22s 559us/step - loss: 0.8921 - acc: 0.6825 - val_loss: 0.8621 - val_acc: 0.7003\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 22s 561us/step - loss: 0.7627 - acc: 0.7315 - val_loss: 0.8102 - val_acc: 0.7144\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 22s 559us/step - loss: 0.6574 - acc: 0.7691 - val_loss: 0.7312 - val_acc: 0.7453\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 22s 559us/step - loss: 0.5697 - acc: 0.7989 - val_loss: 0.7010 - val_acc: 0.7636\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 22s 559us/step - loss: 0.4824 - acc: 0.8299 - val_loss: 0.7528 - val_acc: 0.7520\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 22s 562us/step - loss: 0.3932 - acc: 0.8622 - val_loss: 0.8421 - val_acc: 0.7556\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 23s 571us/step - loss: 0.3160 - acc: 0.8887 - val_loss: 0.8056 - val_acc: 0.7629\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 23s 585us/step - loss: 0.2501 - acc: 0.9097 - val_loss: 0.8349 - val_acc: 0.7651\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 22s 559us/step - loss: 0.1966 - acc: 0.9308 - val_loss: 0.9686 - val_acc: 0.7574\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 22s 559us/step - loss: 0.1708 - acc: 0.9389 - val_loss: 1.0146 - val_acc: 0.7590\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 22s 559us/step - loss: 0.1440 - acc: 0.9499 - val_loss: 1.0466 - val_acc: 0.7569\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 22s 559us/step - loss: 0.1339 - acc: 0.9535 - val_loss: 1.3128 - val_acc: 0.7444\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 22s 562us/step - loss: 0.1265 - acc: 0.9552 - val_loss: 1.0966 - val_acc: 0.7680\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 24s 598us/step - loss: 0.1121 - acc: 0.9609 - val_loss: 1.2415 - val_acc: 0.7424\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 24s 596us/step - loss: 0.1094 - acc: 0.9626 - val_loss: 1.1363 - val_acc: 0.7574\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 24s 599us/step - loss: 0.1101 - acc: 0.9617 - val_loss: 1.2514 - val_acc: 0.7438\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 24s 589us/step - loss: 0.0976 - acc: 0.9659 - val_loss: 1.3814 - val_acc: 0.7515\n",
      "Error for model 2: 0.7525999999999999\n"
     ]
    }
   ],
   "source": [
    "def all_cnn(model_input: Tensor) -> training.Model:\n",
    "    \n",
    "    x = Conv2D(96, kernel_size=(3, 3), activation='relu', padding = 'same')(model_input)\n",
    "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same', strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same', strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(10, (1, 1))(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation(activation='softmax')(x)\n",
    "        \n",
    "    model = Model(model_input, x, name='all_cnn')\n",
    "    \n",
    "    return model\n",
    "all_cnn_model = all_cnn(model_input)\n",
    "_, all_cnn_weight_file = compile_and_train(all_cnn_model, NUM_EPOCHS)\n",
    "\n",
    "\n",
    "print('Error for model 2:', 1 - evaluate_error(all_cnn_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 7s 176us/step - loss: 1.8819 - acc: 0.2921 - val_loss: 1.6315 - val_acc: 0.3950\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 7s 163us/step - loss: 1.5991 - acc: 0.4081 - val_loss: 1.4645 - val_acc: 0.4568\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.4690 - acc: 0.4650 - val_loss: 1.3669 - val_acc: 0.5036\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 7s 163us/step - loss: 1.3949 - acc: 0.4920 - val_loss: 1.3263 - val_acc: 0.5159\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 7s 163us/step - loss: 1.3434 - acc: 0.5125 - val_loss: 1.2787 - val_acc: 0.5361\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.2970 - acc: 0.5293 - val_loss: 1.2211 - val_acc: 0.5532\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.2523 - acc: 0.5499 - val_loss: 1.2226 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.2144 - acc: 0.5649 - val_loss: 1.1043 - val_acc: 0.6110\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.1786 - acc: 0.5784 - val_loss: 1.1570 - val_acc: 0.5877\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 1.1526 - acc: 0.5899 - val_loss: 1.0767 - val_acc: 0.6210\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.1216 - acc: 0.5987 - val_loss: 1.0976 - val_acc: 0.6042\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.1007 - acc: 0.6078 - val_loss: 1.0191 - val_acc: 0.6330\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 7s 163us/step - loss: 1.0767 - acc: 0.6177 - val_loss: 1.0615 - val_acc: 0.6194\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 1.0549 - acc: 0.6254 - val_loss: 1.0230 - val_acc: 0.6311\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.0324 - acc: 0.6327 - val_loss: 0.9944 - val_acc: 0.6461\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.0217 - acc: 0.6343 - val_loss: 0.9640 - val_acc: 0.6563\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.0118 - acc: 0.6391 - val_loss: 0.9060 - val_acc: 0.6815\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 0.9909 - acc: 0.6495 - val_loss: 0.9287 - val_acc: 0.6729\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 0.9800 - acc: 0.6541 - val_loss: 0.9116 - val_acc: 0.6769\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 0.9760 - acc: 0.6549 - val_loss: 0.9041 - val_acc: 0.6792\n",
      "Error for model 3: 0.7525999999999999\n"
     ]
    }
   ],
   "source": [
    "def nin_cnn(model_input: Tensor) -> training.Model:\n",
    "    \n",
    "    #mlpconv block 1\n",
    "    x = Conv2D(32, (5, 5), activation='relu',padding='valid')(model_input)\n",
    "    x = Conv2D(32, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(32, (1, 1), activation='relu')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    #mlpconv block2\n",
    "    x = Conv2D(64, (3, 3), activation='relu',padding='valid')(x)\n",
    "    x = Conv2D(64, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(64, (1, 1), activation='relu')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    #mlpconv block3\n",
    "    x = Conv2D(128, (3, 3), activation='relu',padding='valid')(x)\n",
    "    x = Conv2D(32, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(10, (1, 1))(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation(activation='softmax')(x)\n",
    "    \n",
    "    model = Model(model_input, x, name='nin_cnn')\n",
    "    \n",
    "    return model\n",
    "\n",
    "nin_cnn_model = nin_cnn(model_input)\n",
    "\n",
    "\n",
    "_, nin_cnn_weight_file = compile_and_train(nin_cnn_model, NUM_EPOCHS)\n",
    "\n",
    "print('Error for model 3:', 1 - evaluate_error(all_cnn_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for ensemble model: 0.7874\n"
     ]
    }
   ],
   "source": [
    "conv_pool_cnn_model = conv_pool_cnn(model_input)\n",
    "all_cnn_model = all_cnn(model_input)\n",
    "nin_cnn_model = nin_cnn(model_input)\n",
    "\n",
    "conv_pool_cnn_model.load_weights(conv_pool_cnn_weight_file)\n",
    "all_cnn_model.load_weights(all_cnn_weight_file)\n",
    "nin_cnn_model.load_weights(nin_cnn_weight_file)\n",
    "\n",
    "models = [conv_pool_cnn_model, all_cnn_model, nin_cnn_model]\n",
    "\n",
    "\n",
    "# The ensemble classifier\n",
    "def ensemble(models: List [training.Model], model_input: Tensor) -> training.Model:\n",
    "    \n",
    "    outputs = [model.outputs[0] for model in models]\n",
    "    y = Average()(outputs)\n",
    "    \n",
    "    model = Model(model_input, y, name='ensemble')\n",
    "    \n",
    "    return model\n",
    "\n",
    "ensemble_model = ensemble(models, model_input)\n",
    "\n",
    "\n",
    "print('Error for ensemble model:', 1 - evaluate_error(ensemble_model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
